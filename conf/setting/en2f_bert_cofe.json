{
  "dat_name": "polnear-v2-fixed",
  "mod_name": "ModelBert_Cofe",
  "dat_model": "DatasetBert",
  "bert_pretrained": "bert-base-uncased",
  "max_seqs": 300,
  "mod_conf": {
    "tag_size": 7,
    "words_dropout_prob": 0.5,
    "enh": {
      "tag_size": 7,
      "random_seed": 2021,
      "true_pred_rand_prob": [0.5, 0.4, 0.1],
      "hidden_act": "gelu",
      "num_pre_preds": 1,
      "num_pre_tokens": 3,
      "num_nxt_tokens": 3,
      "in_hidden_size": 768,
      "hidden_size": 100,
      "pred_embedding_dim": 100,
      "fc_pe_dropout_prob": 0.5,
      "fc_hc_dropout_prob": 0.5,
      "fc_hp_dropout_prob": 0.5,
      "fc_hn_dropout_prob": 0.5
    }
,
    "bert": {
      "architectures": [
        "BertForMaskedLM"
      ],
      "attention_probs_dropout_prob": 0.1,
      "finetuning_task": null,
      "hidden_act": "gelu",
      "hidden_dropout_prob": 0.1,
      "hidden_size": 768,
      "initializer_range": 0.02,
      "intermediate_size": 3072,
      "layer_norm_eps": 1e-12,
      "max_position_embeddings": 512,
      "model_type": "bert",
      "num_attention_heads": 12,
      "num_hidden_layers": 12,
      "num_labels": 2,
      "output_attentions": false,
      "output_hidden_states": false,
      "pad_token_id": 0,
      "pruned_heads": {},
      "torchscript": false,
      "type_vocab_size": 2,
      "vocab_size": 30522
    }
  }
}